from moenv_crawler import crawl_moenv_xml
import analysis
import pandas as pd
import final_plots


def main():
    print("=== ç©ºæ±™ Ã— æ©Ÿè»Šæ’æ°£æª¢æ¸¬ç«™ å¤§æ•¸æ“šåˆ†æå°ˆæ¡ˆ ===")

    # ==================================================
    # 1ï¸âƒ£ è®€å–æ©Ÿè»Šæ’æ°£æª¢æ¸¬ç«™ XML è³‡æ–™
    #    è³‡æ–™ä¾†æºï¼šç’°å¢ƒéƒ¨ï¼ˆåŸç’°ä¿ç½²ï¼‰å…¬é–‹è³‡æ–™
    # ==================================================
    station_df = crawl_moenv_xml("æ©Ÿè»Šæ’æ°£å®šæª¢ç«™è³‡æ–™.xml")

    # è‹¥è³‡æ–™ç‚ºç©ºï¼Œä»£è¡¨ XML è®€å–å¤±æ•—æˆ–æª”æ¡ˆæœ‰å•é¡Œ
    if station_df.empty:
        print("âŒ æ©Ÿè»Šæª¢æ¸¬ç«™è³‡æ–™ç‚ºç©ºï¼Œå°ˆæ¡ˆçµæŸ")
        return

    # æ¸…ç†è³‡æ–™ï¼ˆç¸£å¸‚åç¨±çµ±ä¸€ã€å»é™¤ç©ºå€¼èˆ‡é‡è¤‡å€¼ï¼‰
    station_df = analysis.clean_data(station_df)

    # å°‡æ•´ç†å¾Œè³‡æ–™å„²å­˜ç‚º CSV èˆ‡ SQLite
    analysis.save_files(station_df)

    # ==================================================
    # 2ï¸âƒ£ è®€å–ç©ºæ°£å“è³ªè³‡æ–™ï¼ˆPM2.5ã€AQIï¼‰
    # ==================================================
    try:
        air_df = pd.read_csv("air_quality.csv")
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° air_quality.csv")
        return

    # çµ±ä¸€ç¸£å¸‚åç¨±ç”¨å­—ï¼ˆè‡º â†’ å°ï¼‰ï¼Œæ–¹ä¾¿å¾ŒçºŒè³‡æ–™åˆä½µ
    air_df["county"] = air_df["county"].str.replace("è‡º", "å°")
    print("âœ… æˆåŠŸè¼‰å…¥ç©ºæ±™è³‡æ–™")

    # ==================================================
    # 3ï¸âƒ£ å„ç¸£å¸‚ã€Œç©ºæ±™ç¨‹åº¦ Ã— æª¢æ¸¬ç«™æ•¸é‡ã€åˆ†æ
    #    ç›®çš„ï¼šæ¯”è¼ƒç©ºæ°£æ±¡æŸ“ç¨‹åº¦èˆ‡æª¢æ¸¬ç«™è¨­ç½®å¯†åº¦
    # ==================================================

    # è¨ˆç®—æ¯å€‹ç¸£å¸‚çš„æ©Ÿè»Šæª¢æ¸¬ç«™ç¸½æ•¸
    station_count = (
        station_df.groupby("city")
        .size()
        .reset_index(name="station_count")
    )

    # è¨ˆç®—å„ç¸£å¸‚å¹³å‡ PM2.5 èˆ‡ AQI
    air_summary = (
        air_df.groupby("county")[["pm2.5", "aqi"]]
        .mean()
        .reset_index()
    )

    # åˆä½µã€Œæª¢æ¸¬ç«™æ•¸é‡ã€èˆ‡ã€Œç©ºæ°£å“è³ªã€è³‡æ–™
    merged_city_df = pd.merge(
        station_count,
        air_summary,
        left_on="city",
        right_on="county",
        how="inner"
    ).drop(columns=["county"])

    # è¼¸å‡ºåˆ†æçµæœä¾›å ±å‘Šæˆ–å¾ŒçºŒä½¿ç”¨
    merged_city_df.to_csv(
        "city_air_vs_station.csv",
        index=False,
        encoding="utf-8-sig"
    )

    print("âœ… å·²ç”¢ç”Ÿ city_air_vs_station.csv")

    # ==================================================
    # 4ï¸âƒ£ é«˜ PM2.5 ç¸£å¸‚çš„è¡Œæ”¿å€æª¢æ¸¬ç«™åˆ†å¸ƒåˆ†æ
    #    ç›®çš„ï¼šæ‰¾å‡ºç©ºæ±™åš´é‡ç¸£å¸‚ä¸­ï¼Œæª¢æ¸¬ç«™é›†ä¸­åœ¨å“ªäº›è¡Œæ”¿å€
    # ==================================================

    # å– PM2.5 å¹³å‡å€¼æœ€é«˜çš„å‰ 5 åç¸£å¸‚
    top_pm25_cities = (
        merged_city_df
        .sort_values("pm2.5", ascending=False)
        .head(5)["city"]
        .tolist()
    )

    # ç¯©é¸å‡ºé€™äº›é«˜ç©ºæ±™ç¸£å¸‚çš„æª¢æ¸¬ç«™è³‡æ–™
    high_pm25_df = station_df[station_df["city"].isin(top_pm25_cities)]

    # è¨ˆç®—ã€Œç¸£å¸‚ Ã— è¡Œæ”¿å€ã€çš„æª¢æ¸¬ç«™æ•¸é‡
    district_summary = (
        high_pm25_df
        .groupby(["city", "district"])
        .size()
        .reset_index(name="station_count")
    )

    # å„²å­˜é«˜ PM2.5 ç¸£å¸‚è¡Œæ”¿å€åˆ†æçµæœ
    district_summary.to_csv(
        "high_pm25_city_district_station.csv",
        index=False,
        encoding="utf-8-sig"
    )

    print("âœ… å·²ç”¢ç”Ÿ high_pm25_city_district_station.csv")

    # ==================================================
    # 5ï¸âƒ£ â­ è‡ªå‹•ç”¢ç”Ÿæœ€çµ‚åˆ†æåœ–è¡¨ï¼ˆå ±å‘Šé‡é»ï¼‰
    # ==================================================
    print("\nğŸ“ˆ è‡ªå‹•ç¹ªè£½æœ€çµ‚åˆ†æåœ–è¡¨...")
    final_plots.run_final_plots()

    print("\n=== å°ˆæ¡ˆåˆ†æå®Œæˆ ===")


# Python ç¨‹å¼é€²å…¥é»
# ç¢ºä¿æ­¤æª”æ¡ˆæ˜¯ã€Œç›´æ¥åŸ·è¡Œã€æ™‚æ‰æœƒåŸ·è¡Œ main()
if __name__ == "__main__":
    main()
